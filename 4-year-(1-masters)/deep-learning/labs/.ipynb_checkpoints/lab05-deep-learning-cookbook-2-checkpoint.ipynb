{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d21a73a",
   "metadata": {},
   "source": [
    "# Training Deep Networks - Optimization and Tips - Part 2\n",
    "\n",
    "In the last exercise, we went over the basic rules for designing neural network models, the correct procedures for training and evaluating them, and we explored the problem of overfitting and how to detect it. Today's exercise will focus on methods that help optimize the training process, enabling you to train models faster and more reliably.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f866a73",
   "metadata": {},
   "source": [
    "## 1. Regularization\n",
    "\n",
    "The goal of regularization is to prevent overfitting of the network, i.e., we want to avoid allowing any input or weight to excessively influence the outcome. By using regularization, we can also use larger networks without the risk of overfitting; the larger the network, the less likely it is that regularization will increase the *bias*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dd15c4",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 1.1. $L_{1}$ Regularization\n",
    "\n",
    "$L_{1}$ regularization adds the sum of the absolute values of the weights to the objective function, which reduces the coefficients of less significant features close to zero. As a result, some features are ignored, and the network learns a sparse representation.\n",
    "\n",
    "\\begin{equation}\n",
    "J(W, b) = \\frac{1}{m} \\sum_{i=1}^{m} L(\\hat{y}^{2} - y^{2}) + \\frac{\\lambda}{2m} \\sum_{l=1}^{L} \\left \\|w^{[l]}\\right \\|,\n",
    "\\end{equation}\n",
    "\n",
    "where $L$ is the loss function, $\\left \\|w^{[l]}\\right \\|$ is the sum of the absolute values of all weights, and $\\lambda$ is the regularization hyperparameter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c8b7d3",
   "metadata": {},
   "source": [
    "### 1.2. $L_{2}$ regularizácia\n",
    "\n",
    "$L_{2}$ regularizácia zabezpečuje, že hodnoty váh ostanú v istom intervale a tak sa sieť nebude nadmerne spoliehať na ani jednu z nich. Implementujeme ju rozšírením výpočty chyby siete:\n",
    "\n",
    "\\begin{equation}\n",
    "J(W, b) = \\frac{1}{m} \\sum_{i=1}^{m} L(\\hat{y}^{2} - y^{2}) + \\frac{\\lambda}{2m} \\sum_{l=1}^{L} \\left \\|w^{[l]}\\right \\|_{F}^{2},\n",
    "\\end{equation}\n",
    "\n",
    "kde $L$ je chybová funkcia, $\\left \\|w^{[l]}\\right \\|_{F}^{2}$ je tzv. Frobeniusova norma váh a $\\lambda$ je hyperparameter regularizácie. Frobeniusova norma matice sa vypočíta nasledovne:\n",
    "\n",
    "\\begin{equation}\n",
    "\\left \\|w^{[l]}\\right \\|_{F}^{2} = \\sum_{i=1}^{n^{[l-1]}} \\sum_{j=1}^{n^{[l]}}(w_{ij}^{[l]})^{2}\n",
    "\\end{equation}\n",
    "\n",
    "pre *l*-tú vrstvu siete. Spôsob aktualizácia hodnoty váhy sa potom vykoná podľa vzorca:\n",
    "\n",
    "\\begin{equation}\n",
    "\\Delta w^{[l]} = \\frac{\\delta J}{\\delta w^{[l]}} + \\frac{\\lambda}{m}w^{[l]}\n",
    "\\end{equation}\n",
    "\n",
    "pre *l*-tú vrstvu siete.\n",
    "\n",
    "Nevýhodou $L_{2}$ regularizácie je, že samotná $\\lambda$ je ďalší hyperparameter, ktorého hodnotu vieme vhodne nastaviť len spôsobom pokus-omyl. Čím je $\\lambda$ väčšia, tým viac sa budú hodnoty váh pohybovať okolo 0, tým pádom niektoré neuróny akokeby boli \"vypnuté\", vôbec ich sieť nebude používať - prakticky pracujeme s menšou sieťou. Ďalším dôsledkom použitia regularizácie je to, že suma vstupov neurónu bude takisto okolo 0, tým pádom sa použije iba lineárna časť aktivačných funkcií ako napr. sigmoidálna, a tým pádom nevieme pridať nelinearity do rozhodovania siete, teda zabránime pretrénovaniu.\n",
    "\n",
    "$L_{2}$ regularizáciu v *PyTorchi* vieme použiť nastavením parametra `weight_decay` pre optimalizátor pri definícii trénovania (viď [dokumentácia napr. pre Adam](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4976963e",
   "metadata": {},
   "source": [
    "### 1.3. Dropout\n",
    "\n",
    "Dropout je alternatívny spôsob regularizácie, kde pre niektoré vrstvy (alebo každú vrstvu) v sieti určíme pravdepodobnosť toho, že náhodne vypneme niektoré neuróny - to znamená, že odstránime všetky vstupné a výstupné synapsie daného neurónu pre konkrétny výpočet, pracujeme teda s menšou sieťou. Efekt tejto metódy je podobný ako v prípade $L_{2}$ regularizácie - sieť sa naučí nespoliehať sa na žiadny vstup príliš, keďže nemá garantované, že daný vstup bude vždy k dispozícii. Čím je viac pravdepodobné, že sa sieť v danej vrstve pretrénuje, tým vyššia by mala byť pravdepodobnosť *dropoutu*. Pravdepodobnosť 0.0 znamená, že *dropout* nepoužijeme.\n",
    "\n",
    "*Dropout* sa najčastejšie použije v počítačovom videní, ak nemáme k dispozícii veľa trénovacích dát. Nevýhoda *dropoutu* je to, že chyba siete $J$ nie je jasne definovaná, a práve preto jej hodnota nemusí klesať po každej iterácii trénovania. *Dropout* sa zvyčajne nepoužije vo vstupnej vrstve, ak áno, tak s hodnotou okolo 0.0.\n",
    "\n",
    "V *PyTorchi* *dropout* použijeme pridaním špeciálnej `Dropout` vrstvy ([dokumentácia](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87aa858f",
   "metadata": {},
   "source": [
    "### 1.4. Augmentácia dát\n",
    "\n",
    "Spôsobom riešenia malého množstva trénovacích údajov je augmentácia datasetu, teda rozšírenie datasetu algoritmickými spôsobmi. V prípade obrázkov je to najčastejšie prevrátenie obrazu (horizontálne alebo vertikálne, podľa typu dát), náhodné ostrihanie obrazu (sústrediť sa na stred obrazu), pridanie skreslení, rotácia obrazu, atď. Treba si dávať pozor, aby tieto úpravy mali zmysel v kontexte datasetu a netreba zabudnúť, že augmentovaný dataset nikdy nebude dosahovať kvalitu väčšieho datasetu s viacerými príkladmi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7e1759",
   "metadata": {},
   "source": [
    "### 1.5. Skoré ukončenie trénovania\n",
    "\n",
    "Ak chceme predísť pretrénovaniu siete, stopercentná metóda je ukončenie trénovania vo vhodnom momente. Preto pri každej iterácii trénovania zmeriame trénovaciu a validačnú chybu, a trénovanie ukončíme, ak trénovacia chyba ešte klesá, avšak validačná chyba začne rásť. Nevýhodou tejto metódy je to, že nevieme rozdeliť proces optimalizácie chyby a zabránenie pretrénovaniu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f7e242",
   "metadata": {},
   "source": [
    "## 2. Optimalizačné metódy\n",
    "\n",
    "Cieľom optimalizačných metód je urýchliť konvergenciu siete ku globálnemu minimu. V niektorých prípadoch môžu takisto zabezpečiť, aby sieť vôbec konvergovala k tomuto minimu. Základné optimalizačné metódy sú normalizácia, vhodná inicializácia váh, mini-batch trénovanie a použitie optimalizátorov."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99264d5",
   "metadata": {},
   "source": [
    "### 2. 1. Normalizácia vstupu\n",
    "\n",
    "Normalizácia je základná metóda, ktorá **nikdy neuškodí trénovaniu** a práve preto sa používa veľmi často. Princíp za normalizáciou je skutočnosť, že neurónové siete fungujú najlepšie ak ich vstupy sú z istého intervalu (najčastejšie z rozmedzia 0-1). Z pohľadu chybového priestoru pomocou normalizácie dostaneme viac symetrický tvar chybovej hyperboly, vďaka čomu vieme použiť vyšší učiaci parameter (*learning rate*), vďaka čomu sieť bude konvergovať rýchlejšie a bez oscilácie.\n",
    "\n",
    "Prvý základný spôsob normalizácie je odčítanie priemeru:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mu=\\frac{1}{m} \\sum_{i=1}^{m}x^{(i)}\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "x=x-\\mu\n",
    "\\end{equation}\n",
    "\n",
    "Druhá metóda je normalizácia variácie:\n",
    "\n",
    "\\begin{equation}\n",
    "\\sigma^2=\\frac{1}{n} \\sum_{i=1}^{n} x^{(i)2}\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "x = x / \\sigma^{2},\n",
    "\\end{equation}\n",
    "\n",
    "kde musíme použiť rovnaké hodnoty $\\mu$, resp. $\\sigma^2$ pre validačnú a testovaciu množinu.\n",
    "\n",
    "V *PyTorchi* normalizáciu vieme vykonať pomocou vrstvy `LayerNorm` ([dokumentácia](https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html)), keďže ale normalizáciu aplikujeme zvyčajne len pre vstup, môžeme tieto vstupy upraviť čisto štatistickými výpočtami.\n",
    "\n",
    "Špeciálnym typom normalizácie je *batch* normalizácia, teda normalizácia v rámci *mini-batchu*. Vďaka nej je sieť robustnejšia, keďže je zabezpečaná, že priemer a variancia v rámci *mini-batchu* budú ustálené. Pri použití *batch* normalizácie nemusíme použiť *biasy* v predošlej vrstve, avšak mali by sme použiť trošku väčšie *mini-batche*. *PyTorch* ponúka samostatnú [vrstvu pre batch normalizáciu](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html#torch.nn.BatchNorm2d)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cad9ac",
   "metadata": {},
   "source": [
    "### 2.2. Inicializácia váh\n",
    "\n",
    "Vhodnou inicializáciou váh vieme čiastočne zabrániť problémom *vanishing* a *exploding gradient*, ktoré spomaľujú trénovanie, keďže ak derivácia je príliš nízka alebo vysoká, sieť nedokáže nájsť minimum. Ak všetky váhy siete sú vyššie ako 1, aktivačné hodnoty budú stále vyššie (*explosion*, *exploding gradient*), ak všetky váhy majú hodnotu nižšiu ako 1, aktivácie budú stále nižšie (*implosion*, *vanishing gradient*).\n",
    "\n",
    "Vhodnou inicializáciou teda chceme nastaviť čím väčší počet vstupov, tým menšiu hodnotu váh, pričom chceme zachovať istú variabilitu váh. Táto variabilita by mala byť okolo $\\frac{1}{n}$ (pre ReLU $\\frac{2}{n}$), kde $n$ je počet vstupov (počet neurónov v predošlej vrstve).\n",
    "\n",
    "Vhodná inicializácia závisí od aktivačnej funkcie, pre *ReLU* sa najčastejšie používa inicializácia:\n",
    "\n",
    "\\begin{equation}\n",
    "W^{[l]}=np.random.randn(shape) \\cdot np.sqrt(\\frac{2}{n^{[l-1]}})\n",
    "\\end{equation}\n",
    "\n",
    "a pre *tanh* (Xavierova inicializácia):\n",
    "\n",
    "\\begin{equation}\n",
    "W^{[l]}=np.random.randn(shape) \\cdot np.sqrt(\\frac{1}{n^{[l-1]}}),\n",
    "\\end{equation}\n",
    "\n",
    "resp.\n",
    "\n",
    "\\begin{equation}\n",
    "W^{[l]}=np.random.randn(shape) \\cdot np.sqrt(\\frac{2}{n^{[l-1]} + n^{[l]}})\n",
    "\\end{equation}\n",
    "\n",
    "V *PyTorchi* nájdete niekoľko inicializátorov, [ich zoznam je dostupný tu](https://pytorch.org/docs/stable/nn.init.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57825121",
   "metadata": {},
   "source": [
    "### 2.3. Minibatch trénovanie\n",
    "\n",
    "Ako sme už písali vyššie, vývoj hlbokých modelov je iteratívny proces, a práve preto chceme modely natrénovať a vyhodnotiť čo najrýchlejšie. Na druhej strane ale hlboké učenie funguje pri veľkom množstve údajov. Keby sme váhy aktualizovali vždy nad celým datasetom pomocou *backpropagationu*, váhy by sme aktualizovali len pomaly a nezískali by sme rýchlo prehľad o efektívnosti modelu pre riešenie daného problému. Práve preto zavedieme *mini-batche*, a váhy budeme aktualizovať na základe vypočítaných chýb nad príkladmi z tejto dávky údajov.\n",
    "\n",
    "Ak máme dataset *m* príkladov a nastavíme veľkosť *mini-batchov* na *m*, dostaneme základný *batch gradient descent* (vždy konverguje, avšak potrebuje veľa času medzi dvoma aktualizáciami). Ak veľkosť *mini-batchov* je 1, hovoríme o *stochastic gradient descent* (smeruje k lokálnemu minimu, nikdy nekonverguje, strácame možnosť paralelizovať). Veľký rozdiel medzi *batch* a *mini-batch* trénovaním je to, že pri *batch* trénovaní chyba bude nižšia po každej iterácii. Pri *mini-batch* trénovaní to nemusí platiť, keďže výber príkladov do *mini-batchu* je náhodný, chyba by ale stále mala mať klesajúcu tendenciu.\n",
    "\n",
    "Pri malých datasetoch ($m < 2000$) môžeme použiť *batch* trénovanie, pri väčších datasetoch by sme mali využiť *mini-batche* (zvyčajne veľkosť 64, 128, 256, 512 - dávajte si pozor, aby sa jeden *mini-batch* zmestil do pamäte CPU/GPU). V *PyTorchi* *mini-batche* vieme zadefinovať pomocou parametra `batch_size` v `DataLoaderi` ([dokumentácia](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)). Epocha potom reprezentuje prechádzanie celým datasetom."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9054f7b3",
   "metadata": {},
   "source": [
    "## 3 Optimalizátory\n",
    "\n",
    "Optimalizátory rozširujú základny *backprop*, resp. *gradient descent* algoritmy a upravujú spôsob aktualizácie váh. Sú založené na použití exponenciálnych kĺzavých priemerov, ktoré sú odolnejšie voči osciláciam a odstraňujú šum z číselného radu. Pre ľubovoľnú hodnotu $V$ ho vieme vypočítať podľa vzorca:\n",
    "\n",
    "\\begin{equation}\n",
    "V_{i}=\\beta V_{i-1} + (1-\\beta)x_{i},\n",
    "\\end{equation}\n",
    "\n",
    "pričom $V_{0}=0$. $\\beta$ je hyperparameter, ktorý určuje, posledné približne koľko príkladov z číselného radu beriem do úvahy, t.j. posledných $\\frac{1}{1-\\beta}$ príkladov. Napríklad, ak $\\beta=0.9$, kĺzavý priemer bude vypočítaný na základe posledných desiatich hodnôt.\n",
    "\n",
    "V niektorých prípadoch sa používa aj korekcia *bias*u, a to nasledovne:\n",
    "\n",
    "\\begin{equation}\n",
    "V_{i}=\\frac{\\beta V_{i-1} + (1- \\beta)x_{i}}{1-\\beta^t}\n",
    "\\end{equation}\n",
    "\n",
    "pre *t*-ú epochu, resp. *mini-batch*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a0ddbe",
   "metadata": {},
   "source": [
    "### 3.1. Gradient Descent with Momentum\n",
    "\n",
    "*Gradient Descent with Momentum* je rozšírením základného algoritmu spätného šírenia chyby, v ktorom sa nepoužije samotný vypočítaný gradient $\\frac{\\delta J}{\\delta w}$, ale exponenciálny kĺzavý priemer gradientu. Takto je oscilácia pri trénovaní menšia, korekcia *biasu* zvyčajne nie je potrebná. Algoritmus prebieha nasledovne:\n",
    "\n",
    "1. výpočet gradientu $\\Delta W$ na danom *mini-batche*\n",
    "2. výpočet kĺzavého priemeru\n",
    "\n",
    "\\begin{equation}\n",
    "V_{\\Delta W} = \\beta V_{\\Delta W} + (1 - \\beta)\\Delta W\n",
    "\\end{equation}\n",
    "\n",
    "3. aktualizácia váh\n",
    "\n",
    "\\begin{equation}\n",
    "W=W- \\alpha V_{\\Delta W}\n",
    "\\end{equation}\n",
    "\n",
    "Najčastejšie je hodnota $\\beta$ nastavená na 0.9, a vektor $V_{\\Delta W}$ je inicializovaný ako matica núl."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff7da3f",
   "metadata": {},
   "source": [
    "### 3.2. Root Mean Square Prop (RMSprop)\n",
    "\n",
    "*RMSprop* uses a slightly different approach to calculate the moving average by squaring the matrix $\\Delta W$. This ensures that when the error changes significantly according to a certain weight, the weight change is smaller — resulting in a smaller oscillation. The RMSprop optimizer allows the use of a higher learning rate.\n",
    "\n",
    "1. Gradient calculation $\\Delta W$ on a given *mini-batch*\n",
    "2. Moving average calculation\n",
    "\n",
    "\\begin{equation}\n",
    "S_{\\Delta W} = \\beta_{2} S_{\\Delta W} + (1 - \\beta_{2})\\Delta W^2\n",
    "\\end{equation}\n",
    "\n",
    "3. Weight update\n",
    "\n",
    "\\begin{equation}\n",
    "W=W-\\alpha \\frac{\\Delta W}{\\sqrt{S_{\\Delta W}} + \\epsilon},\n",
    "\\end{equation}\n",
    "\n",
    "where $\\epsilon$ is a small number (around $10^{-8}$).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37493390",
   "metadata": {},
   "source": [
    "### 3.3. Adaptive Moment Estimation (Adam)\n",
    "\n",
    "The Adam optimizer is a combination of the two previous methods:\n",
    "\n",
    "1. Gradient calculation $\\Delta W$ on a given *mini-batch*\n",
    "2. Calculation of moving averages\n",
    "\n",
    "\\begin{equation}\n",
    "V_{\\Delta W} = \\beta_1 V_{\\Delta W} + (1 - \\beta_1)\\Delta W\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "S_{\\Delta W} = \\beta_{2} S_{\\Delta W} + (1 - \\beta_{2})\\Delta W^2\n",
    "\\end{equation}\n",
    "\n",
    "3. Bias correction\n",
    "\n",
    "\\begin{equation}\n",
    "V^{corr}_{\\Delta W}=\\frac{V_{\\Delta W}}{1-\\beta_1^t}\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "S^{corr}_{\\Delta W}=\\frac{S_{\\Delta W}}{1-\\beta_2^t}\n",
    "\\end{equation}\n",
    "\n",
    "4. Weight update\n",
    "\n",
    "\\begin{equation}\n",
    "W=W-\\alpha \\frac{V_{\\Delta w}^{corr}}{\\sqrt{S_{\\Delta W}^{corr}}+\\epsilon}\n",
    "\\end{equation}\n",
    "\n",
    "The Adam optimizer has several hyperparameters:\n",
    "\n",
    "* $\\alpha$ - learning rate, needs to be tuned\n",
    "* $\\beta_1 = 0.9$ typically\n",
    "* $\\beta_2 = 0.999$ typically\n",
    "* $\\epsilon = 10^{-8}$ typically\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dabf068",
   "metadata": {},
   "source": [
    "### 3.4. Learning Rate Decay\n",
    "\n",
    "During training, we ideally want to gradually decrease the learning rate as we approach the minimum. This ensures the network's convergence, which is not guaranteed when using *mini-batches*. There are several methods for reducing the learning rate:\n",
    "\n",
    "1. $\\alpha = \\frac{1}{1 + decay \\cdot epoch} \\cdot \\alpha_0$\n",
    "2. $\\alpha = 0.95^{epoch} \\cdot \\alpha_0$ - exponential decay\n",
    "3. $\\alpha = \\frac{k}{\\sqrt{epoch}} \\cdot \\alpha_0$ or $\\alpha = \\frac{k}{\\sqrt{t}} \\cdot \\alpha_0$ - where $k$ is another hyperparameter and constant, and $t$ is the mini-batch number\n",
    "4. Discrete decay - halve the value after each epoch or mini-batch\n",
    "5. Manual decay\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5951ead8",
   "metadata": {},
   "source": [
    "## 4. Hyperparameter Tuning\n",
    "\n",
    "As you can see, when designing and training deep networks, we use several hyperparameters, such as: learning rate, optimizer parameters, number of layers, number of neurons, learning rate decay, and mini-batch size. In order of importance (how much they affect model accuracy or training speed):\n",
    "\n",
    "1. Learning rate ($\\alpha$)\n",
    "2. Mini-batch size, number of neurons, optimizer parameters\n",
    "3. Number of layers, learning rate decay.\n",
    "\n",
    "The question is, how do we find the right combination of these parameter values for efficient training? Since there are no heuristics or guidelines that work universally, the simplest method is to try random parameter values and compare (cross-validation) the model accuracies with those parameters. This way, we can easily identify which parameters influence the model’s success the most, and focus on those. In the case of discrete parameters, we should choose a suitable scale of possible values and pick random values from it—most commonly a logarithmic scale. In Python, you can implement random selection from a logarithmic scale as follows (for example, for the range $[10^{-4}, 10^0]$):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b48b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = -4 * np.random.ran()  # r in [-4, 0]\n",
    "alpha = 10 ** r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac47670c",
   "metadata": {},
   "source": [
    "You can apply this method to the learning parameter and the moving average parameters (optimizer - selection for $1 - \\beta$).\n",
    "\n",
    "If you find an area where the models are training more accurately, you should focus on it and do a few more iterations of random selections.\n",
    "\n",
    "Another good step is to look for scientific papers on similar tasks from other domains, as you might find an applicable solution. During the model's life cycle, it is necessary to review the hyperparameter settings several times, as the dataset or computing system may have changed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09750e8",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* [Andrew Ng: Improving Deep Neural Networks - Hyperparameter Tuning](https://www.youtube.com/watch?v=1waHlpKiNyY&list=PLkDaE6sCZn6Hn0vK8co82zjQtt3T2Nkqc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
