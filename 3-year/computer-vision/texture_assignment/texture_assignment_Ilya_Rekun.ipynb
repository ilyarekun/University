{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEXTURE SEGMENTATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T19:39:16.877043Z",
     "start_time": "2024-12-14T19:39:16.686035Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1233"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T19:39:16.890297Z",
     "start_time": "2024-12-14T19:39:16.881088Z"
    },
    "id": "XCQniQDoGR_8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import fft\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.ndimage import binary_dilation\n",
    "import cv2\n",
    "from skimage.exposure import rescale_intensity\n",
    "\n",
    "from skimage import (\n",
    "    io, color, morphology, filters, transform, data\n",
    ")\n",
    "from skimage.color import rgb2gray, label2rgb\n",
    "from skimage.filters.rank import entropy\n",
    "from skimage.feature import graycoprops, graycomatrix\n",
    "from skimage.segmentation import find_boundaries, mark_boundaries\n",
    "from skimage.transform import probabilistic_hough_line\n",
    "from skimage.draw import line as skimage_line\n",
    "from skimage.measure import label\n",
    "from skimage.morphology import remove_small_objects, disk\n",
    "import warnings\n",
    "from felzenszwalb_segmentation import segment\n",
    "\n",
    "plt.rc({'family': 'normal', 'weight': 'normal'})\n",
    "plt.rcParams['font.size'] = 18\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# Ignore DeprecationWarning\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning, module='skimage')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIN ALGORITHM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T19:39:16.976683Z",
     "start_time": "2024-12-14T19:39:16.973270Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocessing(img):\n",
    "\n",
    "    # Scale the image to the 0-255 range and convert to unsigned 8-bit integers\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "\n",
    "    sElem = disk(40)\n",
    "    pageFloat = img\n",
    "    # Apply a local mean filter using the structuring element and normalize the result\n",
    "    pageFilt = filters.rank.mean(pageFloat, footprint=sElem) / 255\n",
    "    img_processed = pageFloat - pageFilt\n",
    "\n",
    "    # Adjust the contrast of the image\n",
    "    img_processed = cv2.convertScaleAbs(img_processed, alpha=0.65, beta=0)\n",
    "\n",
    "    # Apply a median blur to reduce noise\n",
    "    img_processed = cv2.medianBlur(np.uint8(img_processed), 5)\n",
    "    # Apply a Gaussian blur for additional smoothing\n",
    "    blurred_img = cv2.GaussianBlur(img_processed, (11, 11), 0)\n",
    "\n",
    "    sElem = disk(60)\n",
    "    pageFloat = blurred_img\n",
    "    pageFilt = filters.rank.mean(pageFloat, footprint=sElem) / 255\n",
    "    # Subtract the second local mean-filtered image from the smoothed image\n",
    "    img_processed = pageFloat - pageFilt\n",
    "\n",
    "    return img_processed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for frequency filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T19:39:17.023883Z",
     "start_time": "2024-12-14T19:39:17.019928Z"
    }
   },
   "outputs": [],
   "source": [
    "def freq_filter(img):\n",
    "    \"\"\"\n",
    "    Perform frequency-based filtering and morphological operations on the input image.\n",
    "\n",
    "    Parameters:\n",
    "    img (ndarray): Input grayscale image.\n",
    "\n",
    "    Returns:\n",
    "    ndarray: Processed binary image after high-pass filtering and morphological operations.\n",
    "    \"\"\"\n",
    "    # Apply a local mean filter with a disk-shaped structuring element (radius=40)\n",
    "    sElem = disk(40)\n",
    "    pageFloat = img\n",
    "    pageFilt = filters.rank.mean(pageFloat, footprint=sElem) / 255\n",
    "    img_processed = pageFloat - pageFilt\n",
    "\n",
    "    # Step 1: Perform Fourier Transform to analyze frequency components\n",
    "    img_f = fft.fft2(img_processed)\n",
    "    zero_center_img_fft = fft.fftshift(img_f)  # Center the zero frequency for better manipulation\n",
    "\n",
    "    # Step 2: Apply high-pass filtering in the frequency domain\n",
    "    pixels = 160  # Threshold to define the high-frequency region to filter out\n",
    "    img_size = img.shape\n",
    "    filt_spect = zero_center_img_fft\n",
    "    filt_spect[img_size[0] // 2 - pixels:img_size[0] // 2 + pixels,\n",
    "    img_size[1] // 2 - pixels:img_size[1] // 2 + pixels] = 0 + 0j  # Set low-frequency region to zero\n",
    "\n",
    "    # Step 3: Perform inverse Fourier Transform to convert back to the spatial domain\n",
    "    inverse_img = fft.ifft2(filt_spect)\n",
    "    real_img = np.abs(inverse_img) * 255  # Take the magnitude and scale to 0-255\n",
    "    real_img_uint8 = real_img.astype(np.uint8)  # Convert to unsigned 8-bit integers\n",
    "\n",
    "    # Step 5: Binarize the image with a threshold\n",
    "    val = real_img_uint8 > 12  # Threshold to distinguish foreground and background\n",
    "    val_uint8 = (val * 255).astype(np.uint8)  # Convert the binary result to 8-bit format\n",
    "\n",
    "    # Step 6: Perform morphological opening to remove small noise\n",
    "    kernel = np.ones((1, 1), np.uint8)  # Small kernel size for precise noise removal\n",
    "    opened_image = cv2.morphologyEx(val_uint8, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # Step 7: Perform morphological closing to fill small gaps in the foreground\n",
    "    kernel = np.ones((4, 4), np.uint8)  # Larger kernel to bridge gaps\n",
    "    closed_image = cv2.morphologyEx(opened_image, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    return closed_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T19:39:17.071234Z",
     "start_time": "2024-12-14T19:39:17.066927Z"
    }
   },
   "outputs": [],
   "source": [
    "def freq_filter1(img):\n",
    "    \"\"\"\n",
    "    Apply a low-pass frequency filter to the input image using Fourier Transform.\n",
    "\n",
    "    Parameters:\n",
    "    img (ndarray): Input grayscale image.\n",
    "\n",
    "    Returns:\n",
    "    ndarray: Reconstructed image after applying the low-pass filter.\n",
    "    \"\"\"\n",
    "    # Scale the image to the range 0-255 and convert to unsigned 8-bit integers\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "\n",
    "    # Define the size of the low-frequency region to retain in the filtered spectrum\n",
    "    pixels = 80\n",
    "\n",
    "    # Perform 2D Fourier Transform to move to the frequency domain\n",
    "    img_fft = fft.fft2(img)\n",
    "    zero_center_img_fft = fft.fftshift(img_fft)  # Shift the zero frequency to the center\n",
    "\n",
    "    # Get the size of the image\n",
    "    img_size = img.shape\n",
    "\n",
    "    # Create an empty array for the filtered spectrum (complex values)\n",
    "    filt_spect = np.zeros(zero_center_img_fft.shape, dtype=np.complex128)\n",
    "\n",
    "    # Retain only the low-frequency components within the defined region\n",
    "    filt_spect[img_size[0] // 2 - pixels:img_size[0] // 2 + pixels,\n",
    "    img_size[1] // 2 - pixels:img_size[1] // 2 + pixels] = \\\n",
    "        zero_center_img_fft[img_size[0] // 2 - pixels:img_size[0] // 2 + pixels,\n",
    "        img_size[1] // 2 - pixels:img_size[1] // 2 + pixels]\n",
    "\n",
    "    # Perform the inverse Fourier Transform to reconstruct the image in the spatial domain\n",
    "    inverseImg = np.abs(fft.ifft2(filt_spect))\n",
    "\n",
    "    return inverseImg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for Hough transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T19:39:17.118919Z",
     "start_time": "2024-12-14T19:39:17.114159Z"
    }
   },
   "outputs": [],
   "source": [
    "def hough_transform(img):\n",
    "    \"\"\"\n",
    "    Perform probabilistic Hough Transform to detect lines in the input binary image.\n",
    "    The parameters for line detection are dynamically adjusted based on the ratio of white pixels.\n",
    "\n",
    "    Parameters:\n",
    "    img (ndarray): Input binary image.\n",
    "\n",
    "    Returns:\n",
    "    ndarray: Binary image with detected lines.\n",
    "    \"\"\"\n",
    "    # Calculate the number of white pixels and their ratio relative to the total pixels\n",
    "    white_pixel_count = np.sum(img > 0)\n",
    "    total_pixel_count = img.shape[0] * img.shape[1]\n",
    "    white_pixel_ratio = 1000 * white_pixel_count / total_pixel_count  # Scale ratio for better parameter adjustment\n",
    "    #print('\\nwhite_pixel_ratio:', white_pixel_ratio)\n",
    "\n",
    "    # Dynamically compute parameters for Hough Transform based on white_pixel_ratio\n",
    "    threshold = int(1.22 * white_pixel_ratio + 0.93)  # Minimum votes needed to detect a line\n",
    "    line_length = int(-1.63 * white_pixel_ratio + 71.76)  # Minimum length of a line segment\n",
    "    line_gap = int(-3.37 * white_pixel_ratio + 134.96)  # Maximum allowed gap between line segments\n",
    "    #print(f\"threshold: {threshold}, line_length: {line_length}, line_gap: {line_gap}\")\n",
    "\n",
    "    # Apply probabilistic Hough Transform to detect lines\n",
    "    lines = probabilistic_hough_line(img, threshold=threshold, line_length=line_length, line_gap=line_gap)\n",
    "\n",
    "    # Initialize a blank image to draw the detected lines\n",
    "    result = np.zeros_like(img)\n",
    "    for line in lines:\n",
    "        p0, p1 = line  # Extract start and end points of each line\n",
    "        rr, cc = skimage_line(p0[1], p0[0], p1[1], p1[0])  # Generate line coordinates\n",
    "        result[rr, cc] = 255  # Draw the line in white on the result image\n",
    "\n",
    "    # Step 1: Morphological opening to remove small noise\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    opened_image = cv2.morphologyEx(result, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # Step 2: Morphological closing to fill small gaps in detected lines\n",
    "    kernel = np.ones((4, 4), np.uint8)\n",
    "    closed_image = cv2.morphologyEx(opened_image, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Step 3: Additional opening to refine the result\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    opened_image = cv2.morphologyEx(closed_image, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    return closed_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for combining image and lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T19:39:17.165358Z",
     "start_time": "2024-12-14T19:39:17.162178Z"
    }
   },
   "outputs": [],
   "source": [
    "def combine(blur, lines):\n",
    "    \"\"\"\n",
    "    Combine a grayscale image with a binary line image by overlaying the lines on the grayscale image.\n",
    "\n",
    "    Parameters:\n",
    "    blur (ndarray): Grayscale image with values in the range [0, 255] or [0, 1].\n",
    "    lines (ndarray): Binary image with line information, values in the range [0, 255] or [0, 1].\n",
    "\n",
    "    Returns:\n",
    "    ndarray: Grayscale image with lines overlaid in white.\n",
    "    \"\"\"\n",
    "    # Ensure the grayscale image is in the range 0-255\n",
    "    blur = (blur * 255).astype(np.uint8) if blur.max() <= 1 else blur\n",
    "\n",
    "    # Ensure the binary line image is in the range 0-255\n",
    "    lines = (lines * 255).astype(np.uint8) if lines.max() <= 1 else lines\n",
    "\n",
    "    # Create a copy of the grayscale image to avoid modifying the original\n",
    "    output_image = blur.copy()\n",
    "\n",
    "    # Overlay the lines: set pixels to white (255) where the binary line image has 255\n",
    "    output_image[lines == 255] = 255\n",
    "\n",
    "    return output_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for Felzenszwalb Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T19:39:17.211593Z",
     "start_time": "2024-12-14T19:39:17.208763Z"
    }
   },
   "outputs": [],
   "source": [
    "def felz_segm(im_contrast):\n",
    "    \"\"\"\n",
    "    Apply Felzenszwalb segmentation to the input grayscale image.\n",
    "\n",
    "    Parameters:\n",
    "    im_contrast (ndarray): Grayscale input image.\n",
    "\n",
    "    Returns:\n",
    "    ndarray: Segmented image with regions labeled as unique integers.\n",
    "    \"\"\"\n",
    "    # Convert the grayscale image to RGB by stacking the single channel three times\n",
    "    im_contrast1 = np.stack([im_contrast] * 3, axis=-1)\n",
    "\n",
    "    #print(im_contrast1.shape)\n",
    "\n",
    "    # Apply Felzenszwalb segmentation with specified hyperparameters\n",
    "    segmented_image = segment(im_contrast1, 0, 55, 900)\n",
    "\n",
    "    return segmented_image.astype(np.uint8)  # Convert the segmented result to uint8 format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T19:39:17.258399Z",
     "start_time": "2024-12-14T19:39:17.254911Z"
    }
   },
   "outputs": [],
   "source": [
    "def postprocessing(img):\n",
    "    \"\"\"\n",
    "    Apply postprocessing to the input image, including grayscale conversion and morphological closing.\n",
    "\n",
    "    Parameters:\n",
    "    img (ndarray): Input image, either grayscale or RGB.\n",
    "\n",
    "    Returns:\n",
    "    ndarray: Processed image after applying morphological closing.\n",
    "    \"\"\"\n",
    "    # Check if the image is in RGB format and convert it to grayscale if necessary\n",
    "    if len(img.shape) == 3 and img.shape[2] == 3:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "    # Perform morphological opening to remove small noise\n",
    "\n",
    "    kernel = np.ones((7, 7), np.uint8)\n",
    "    opened_image = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    img_inverted = cv2.bitwise_not(opened_image)\n",
    "    # Apply the morphological closing operation (dilation followed by erosion)\n",
    "    #kernel = np.ones((5, 5), np.uint8)\n",
    "    #closed_image = cv2.morphologyEx(img_inverted, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    img_normalized = img_inverted.astype(np.float32) / 255.0\n",
    "\n",
    "    return img_normalized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algo function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T19:39:17.396911Z",
     "start_time": "2024-12-14T19:39:17.392485Z"
    }
   },
   "outputs": [],
   "source": [
    "def main_alg(data_folder_path):\n",
    "\n",
    "    count = len([f for f in os.listdir(data_folder_path) if f.endswith('.png')])\n",
    "    if not os.path.exists(\"output\"):\n",
    "        os.makedirs(\"output\")\n",
    "\n",
    "    # Main algorithm loop\n",
    "    for idx in range(1, count+1):\n",
    "        input_path = f\"data/tm{idx}_1_1.png\"\n",
    "        if input_path.endswith('.png'):  # Check if the file has a .png extension (modify if needed)\n",
    "            image = plt.imread(input_path)\n",
    "        # Apply preprocessing steps\n",
    "        blur = preprocessing(image)\n",
    "        # Apply frequency domain filtering\n",
    "        blur = freq_filter1(blur)\n",
    "\n",
    "        # Apply frequency-based texture extraction\n",
    "        lines = freq_filter(image)\n",
    "        # Perform Hough Transform to detect lines\n",
    "        lines = hough_transform(lines)\n",
    "\n",
    "        # Combine the blurred image and detected lines to generate texture\n",
    "        texture = combine(blur, lines)\n",
    "\n",
    "        # Apply segmentation to refine the texture\n",
    "        texture = felz_segm(texture)\n",
    "\n",
    "        # Apply morphology\n",
    "        texture = postprocessing(texture)\n",
    "\n",
    "\n",
    "\n",
    "        imgx = Image.fromarray((texture * 255).astype(np.uint8))  # Convert to 8-bit image\n",
    "        output_path = f\"output/seg{idx}_1_1.png\"\n",
    "\n",
    "        imgx.save(output_path)  # Save the image to the specified path\n",
    "        print(f\"Image saved: {output_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling algo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T19:43:13.650304Z",
     "start_time": "2024-12-14T19:39:17.440225Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7800/3010502576.py:44: UserWarning: Possible precision loss converting image of type float32 to uint8 as required by rank filters. Convert manually using skimage.util.img_as_ubyte to silence this warning.\n",
      "  lines = freq_filter(image)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved: output/seg1_1_1.png\n",
      "Image saved: output/seg2_1_1.png\n",
      "Image saved: output/seg3_1_1.png\n",
      "Image saved: output/seg4_1_1.png\n",
      "Image saved: output/seg5_1_1.png\n",
      "Image saved: output/seg6_1_1.png\n",
      "Image saved: output/seg7_1_1.png\n",
      "Image saved: output/seg8_1_1.png\n",
      "Image saved: output/seg9_1_1.png\n",
      "Image saved: output/seg10_1_1.png\n",
      "Image saved: output/seg11_1_1.png\n",
      "Image saved: output/seg12_1_1.png\n",
      "Image saved: output/seg13_1_1.png\n",
      "Image saved: output/seg14_1_1.png\n",
      "Image saved: output/seg15_1_1.png\n",
      "Image saved: output/seg16_1_1.png\n",
      "Image saved: output/seg17_1_1.png\n",
      "Image saved: output/seg18_1_1.png\n",
      "Image saved: output/seg19_1_1.png\n",
      "Image saved: output/seg20_1_1.png\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    data_folder_path = 'data'\n",
    "    #output_folder_path = 'output'\n",
    "    main_alg(data_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T19:43:13.671391Z",
     "start_time": "2024-12-14T19:43:13.669445Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "041c59545ba646e7a6041ccf684babb1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0f99ff1edde140f38d2bd075e45439d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1d26e82d5b514c9b82ca4cf104fab80f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2577ded8dd424e2ba3a149e685f51c59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9db48756f38a432c9ad8c12101fbc510",
       "IPY_MODEL_a5aaea344a184cc69718fa7e8704d17e",
       "IPY_MODEL_a7ffd977744e478dba743d22fd582c85"
      ],
      "layout": "IPY_MODEL_edbed059431e446fb8458907bc272dff"
     }
    },
    "32e4d4790b3d42c9b0a9c5b7d9576194": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ab7236f3def43a6abc0606125ac0eda": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "61d266110fe44b369c310210fdacf1ea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "74f8ee448aa345169e264a71d51e65d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "777b8de8be6747c0b0a4e16f0430bb63": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "91db16f45e66411ea46c11f77cb514af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "99c2c62efc9d47ae9f49b7a239340ddb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cbe9f4064fed430fb0e80e69268e9f9d",
      "placeholder": "​",
      "style": "IPY_MODEL_0f99ff1edde140f38d2bd075e45439d7",
      "value": "100%"
     }
    },
    "9db48756f38a432c9ad8c12101fbc510": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0f964d810784dc3b1d66d2a6f93466e",
      "placeholder": "​",
      "style": "IPY_MODEL_91db16f45e66411ea46c11f77cb514af",
      "value": "100%"
     }
    },
    "a0f964d810784dc3b1d66d2a6f93466e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a5aaea344a184cc69718fa7e8704d17e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ce0b5683284548279531459d41f70033",
      "max": 251,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_041c59545ba646e7a6041ccf684babb1",
      "value": 251
     }
    },
    "a7ffd977744e478dba743d22fd582c85": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_61d266110fe44b369c310210fdacf1ea",
      "placeholder": "​",
      "style": "IPY_MODEL_5ab7236f3def43a6abc0606125ac0eda",
      "value": " 251/251 [03:29&lt;00:00,  1.02it/s]"
     }
    },
    "c566e4b7d8a74d1ab53dcf0695905130": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_777b8de8be6747c0b0a4e16f0430bb63",
      "max": 247,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_74f8ee448aa345169e264a71d51e65d7",
      "value": 247
     }
    },
    "cbe9f4064fed430fb0e80e69268e9f9d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce0b5683284548279531459d41f70033": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cfe7660bbe9c4a78bd9106c2111ec366": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_99c2c62efc9d47ae9f49b7a239340ddb",
       "IPY_MODEL_c566e4b7d8a74d1ab53dcf0695905130",
       "IPY_MODEL_f5c5e73f8f564815a7c4b7121aa364da"
      ],
      "layout": "IPY_MODEL_32e4d4790b3d42c9b0a9c5b7d9576194"
     }
    },
    "edbed059431e446fb8458907bc272dff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f5c5e73f8f564815a7c4b7121aa364da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1d26e82d5b514c9b82ca4cf104fab80f",
      "placeholder": "​",
      "style": "IPY_MODEL_f868fc706a1b485b8138ca83410f3bdf",
      "value": " 247/247 [03:11&lt;00:00,  1.16it/s]"
     }
    },
    "f868fc706a1b485b8138ca83410f3bdf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
