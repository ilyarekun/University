{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28b38ed4",
   "metadata": {},
   "source": [
    "# Convolution\n",
    "\n",
    "In deep learning, where images are often used, more advanced mathematical operations such as convolution are applied. Convolution represents an operation between two functions that expresses how the application of one function affects the shape of the other. In the context of deep learning and image processing, convolution enables the detection of features (lines, edges, higher-level structures).\n",
    "\n",
    "Before we look at how to apply convolution, let's focus on how images are represented in computers:\n",
    "1. **How are images encoded and stored in computers?**  \n",
    "2. **When training neural networks, it is often necessary to normalize input data to a certain range (most commonly 0 - 1). How can data representing images be normalized for deep neural networks?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86eb57b7",
   "metadata": {},
   "source": [
    "In deep neural networks, convolution is performed by applying a filter to an image (the filter dimensions are usually smaller, and both often have a square shape). The computation is then carried out by element-wise multiplication of two \"matrices\" followed by summing the products. The output will be another matrix, with its dimensions determined by additional convolution parameters such as *padding* and *stride*.\n",
    "\n",
    "The simplest case of applying convolution is demonstrated in the following example, where the input image has a size of *5 x 5* and the filter has dimensions of *3 x 3*:\n",
    "\n",
    "![Convolution example](lab02/conv_example_1.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a69505a",
   "metadata": {},
   "source": [
    "We start applying the filter in the top-left corner:\n",
    "\n",
    "![Convolution step 1](lab02/conv_first_step.jpg)\n",
    "\n",
    "where the result of the operation will be:\n",
    "\n",
    "\\begin{equation*}\n",
    "3 \\cdot 0 + 2 \\cdot 1 + 1 \\cdot 2 + 0 \\cdot 2 + 4 \\cdot 2 + 2 \\cdot 0 + 0 \\cdot 0 + 2 \\cdot 1 + 3 \\cdot 2 = 20\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3f5f10",
   "metadata": {},
   "source": [
    "In the next step, we move the filter to the right (according to the *stride*, for now by 1), and if we reach the end of the row, we move the filter one step down and return it to the beginning of the row. We continue this way until we reach the bottom-right corner of the image.\n",
    "\n",
    "**Calculate the remaining values after applying the filter (the output will be a 3 x 3 matrix).**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248bd2df",
   "metadata": {},
   "source": [
    "## Convolution - Real Application\n",
    "\n",
    "To better understand the essence and usefulness of convolution, let's look at an example of applying a filter to detect horizontal edges. In the early development of convolutional neural networks, it was precisely about adding existing filters to the neural network. However, deep learning later enabled the training of the filters themselves. **What will be the result of applying the filter to the image in the following case? What effect does it have on the image? How is the detected feature, i.e., the edge, represented?**\n",
    "\n",
    "![Convolution edge](lab02/conv_edge.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07f2736",
   "metadata": {},
   "source": [
    "## Pooling\n",
    "\n",
    "In convolutional networks, besides convolution itself, the pooling operation is also often used, with the aim of reducing the dimensions of the input image while preserving the information contained in it. During pooling, we traverse the image in a similar manner as in the case of convolution, but in pooling, we do not use a filter—only a small \"window\" from the image—and compute the output based on the specific type of pooling. There are different types of pooling, and today we will look at the two most common:\n",
    "\n",
    "- **max pooling** - selects the maximum value from the window  \n",
    "- **average pooling** - calculates the average of the values in the window.  \n",
    "\n",
    "**Apply both types of pooling with dimensions *2 x 2* and a *stride* of 1 to the previous examples. What differences do you observe in the results?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0207bbc0",
   "metadata": {},
   "source": [
    "# Implementation of Convolution and Pooling\n",
    "\n",
    "In this exercise, we will implement the basic operations of convolutional neural networks, namely convolution and *pooling*. We will program in the Python programming language. For the implementation, we will use the `numpy` library, which is very commonly used in deep learning projects, and other libraries such as `tensorflow` and `pytorch` are built on top of it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444a837f",
   "metadata": {},
   "source": [
    "## 1. Solution Structure\n",
    "\n",
    "[You can find the skeleton of today's solution here](lab02/lab02.py) or you can download this Jupyter notebook and work directly in it.\n",
    "\n",
    "At the beginning, we will import the `numpy` library and define a few sample examples for images and filters:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e54f9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "image1 = np.array([\n",
    "    [3, 2, 1, 2, 0],\n",
    "    [0, 4, 2, 0, 1],\n",
    "    [0, 2, 3, 1, 1],\n",
    "    [1, 3, 4, 0, 0],\n",
    "    [2, 1, 2, 1, 0]\n",
    "])\n",
    "\n",
    "filter1 = np.array([\n",
    "    [0, 1, 2],\n",
    "    [2, 2, 0],\n",
    "    [0, 1, 2]\n",
    "])\n",
    "\n",
    "image2 = np.array([\n",
    "    [1, 1, 1, 1, 1, 1],\n",
    "    [1, 1, 1, 1, 1, 1],\n",
    "    [1, 1, 1, 1, 1, 1],\n",
    "    [0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0]\n",
    "])\n",
    "\n",
    "filter2 = np.array([\n",
    "    [1, 2, 1],\n",
    "    [0, 0, 0],\n",
    "    [-1, -2, -1]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb98c6ef",
   "metadata": {},
   "source": [
    "The script declares six functions that we will implement in the following steps—three helper functions and three containing the implementation of convolution, max pooling, and average pooling. You can find their detailed description in the comments, but we can summarize the purpose of these functions as follows:\n",
    "\n",
    "- `get_result_array` - creates an empty n-dimensional array with values initialized to 0. Its task is to calculate the dimensions of the result map after applying convolution or *pooling*.\n",
    "- `get_padding_value` - calculates the required padding based on the parameters of convolution/*pooling*.\n",
    "- `get_padded_image` - adds *padding* to the original input image according to the *padding* value.\n",
    "- `convolve` - performs convolution with the given parameters.\n",
    "- `maxPool` - performs *max pooling* with the given parameters.\n",
    "- `avgPool` - performs *average pooling* with the given parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca4389c",
   "metadata": {},
   "source": [
    "## 2. `get_result_array`\n",
    "\n",
    "Before we dive into implementing the convolution and *pooling* operations, we need to understand the role of the *stride* and *padding* parameters.\n",
    "\n",
    "*Stride* represents how far we move the convolution or *pooling* filter by one step of computation. It most commonly has a value of 1, especially when using *padding*. In today's exercise, we will assume its value is 1; later, you can extend your solution to support other *stride* values.\n",
    "\n",
    "*Padding* is the adjustment of the input image before applying convolution or *pooling*. Although there are several variants, the most commonly used is *zero padding*, which means adding zero values to the edges of the image in all directions. Of the possible ways to use *padding*, today we will implement two: *no padding* (i.e., we do not apply *padding* to the image at all) and *same padding*, which means adding the same number of zeros in every direction so that the filter fits into the dimensions of the expanded image without ignoring any part of the image.\n",
    "\n",
    "If the above assumptions hold, we can calculate the dimensions of the output feature map using the following formula:\n",
    "\n",
    "\\begin{equation*}\n",
    "m_{d} = \\frac{I_{d} - k_{d} + 2 \\cdot P}{S} + 1,\n",
    "\\end{equation*}\n",
    "\n",
    "where $m$ is the map, $I$ is the image, $k$ is the filter (or *kernel*), $P$ is the *padding* value (the number of added zeros), $S$ is the *stride*, and $d$ is the dimension (width or height). However, since we very often use square images in convolution, this equation applies to both dimensions simultaneously.\n",
    "\n",
    "**Implement the `get_result_array` function to return an n-dimensional array of values initialized to 0.** The input parameters of the function have the following meanings:\n",
    "\n",
    "- `image_shape` - a pair of integer values representing the dimensions of the input image (height x width) ($I$)  \n",
    "- `kernel_shape` - a pair of integer values representing the dimensions of the filter (height x width) ($k$)  \n",
    "- `stride` - an integer value representing the shift after applying the operation ($S$)  \n",
    "- `P` - *padding* value, an integer ($P$)  \n",
    "\n",
    "In the function, you should perform the following steps:\n",
    "\n",
    "1. Calculate the dimensions of the output feature map according to the above formula.  \n",
    "2. Check if the resulting dimensions are integers; if not, raise an appropriate error.  \n",
    "3. The function should return a two-dimensional array of zeros with the calculated dimensions (height x width).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1f7b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_array(image_shape, kernel_shape, stride, P):\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76553eb6",
   "metadata": {},
   "source": [
    "## 3. `get_padding_value`\n",
    "\n",
    "In the next step, we will implement the `get_padding_value` function, which will calculate the *padding* value, i.e., the number of zeros added according to the given parameter settings. As mentioned in point 2, today we will use only two types of *padding*: *no padding* and *same padding*. In the function, we also need to check whether the parameter settings result in a valid operation when using *padding*.\n",
    "\n",
    "In the case of *no padding*, we do not need to add zeros, so the *padding* value is zero. For *same padding*, we will assume that *stride* is 1, and then the *padding* value can be calculated using the formula (derived from the above formula, where $m = I$):\n",
    "\n",
    "\\begin{equation*}\n",
    "P_{d} = \\frac{k_{d} - 1}{2},\n",
    "\\end{equation*}\n",
    "\n",
    "where $P_{d}$ is the *padding* value in dimension $d$ and $k_{d}$ is the filter size in that dimension. If we are working with a square filter, the *padding* value will be the same in both directions.\n",
    "\n",
    "**Implement the `get_padding_value` function to calculate the *padding* value and also check if all parameter constraints are met:**\n",
    "\n",
    "- The `padding` parameter can take the values `'none'` and `'same'`.\n",
    "- In the case of *same padding*, the `stride` parameter must have a value of `1`.\n",
    "\n",
    "The function will return a single integer and has the following parameters:\n",
    "\n",
    "- `kernel_shape` - a pair of integer values representing the dimensions of the filter (height x width) ($k$)\n",
    "- `stride` - an integer value representing the shift after applying the operation ($S$)\n",
    "- `padding` - a string with the value `'none'` for *no padding* or `'same'` for *same padding*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034ac7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padding_value(kernel_shape, stride, padding):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3560eecb",
   "metadata": {},
   "source": [
    "## 4. `get_padded_image`\n",
    "\n",
    "Ďalšia funkcia vykoná *padding* nad obrázkom, t.j. pridá potrebný počet 0 vo všetkých smeroch, pôvodný obrázok sa nachádza potom v strede rozšíreného obrázka. Funkcia má dva parametre:\n",
    "\n",
    "- `image` - pôvodný obrázok\n",
    "- `P` - *padding* hodnota, počet pridaných núl.\n",
    "\n",
    "**Implementujte funkciu `get_padded_image`, ktorá vráti numpy pole s rozšíreným obrázkom. Pôvodnú premennú nemeňte.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058ce959",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padded_image(image, P):\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310ba09d",
   "metadata": {},
   "source": [
    "## 5. `convolve`\n",
    "\n",
    "In this step, we will implement convolution. To preprocess the image and prepare the output feature map, we can use the helper functions we have already created; our only task is to fill the prepared feature map with values by applying the convolution. The function has four parameters:\n",
    "\n",
    "- `image` - an n-dimensional array representing the input image\n",
    "- `kernel` - an n-dimensional array representing the convolution filter\n",
    "- `stride` - an integer value representing the shift after applying the operation\n",
    "- `padding` - a string with the value `'none'` for *no padding* or `'same'` for *same padding*\n",
    "\n",
    "**Implement the `convolve` function so that it returns the feature map. Do not modify the original variables `image` and `kernel`.**\n",
    "\n",
    "After implementation, you can test your solution with predefined examples or with an image of your choice (make sure to adjust the parameter values in the `main` function).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38741ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve(image, kernel, stride=1, padding='none'):\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6065468b",
   "metadata": {},
   "source": [
    "## 6. `maxPool` and `avgPool`\n",
    "\n",
    "In the final step, we need to implement the functions for *pooling*. In the script, you have two declared functions for *max pooling* and *average pooling*, and their structure is very similar to the convolution solution. The only difference is in the calculation of values in the feature map. Both functions have four parameters:\n",
    "\n",
    "- `image` - an n-dimensional array representing the input image\n",
    "- `kernel_size` - a pair of integer values representing the dimensions of the input image (height x width)\n",
    "- `stride` - an integer value representing the shift after applying the operation\n",
    "- `padding` - a string with the value `'none'` for *no padding* or `'same'` for *same padding*\n",
    "\n",
    "**Implement and test the `max_pool` and `avg_pool` functions so that they return the feature map after applying the *pooling* operation. Do not modify the values of the input variables.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70de5d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool(image, kernel_size, stride=1, padding='none'):\n",
    "    return image\n",
    "\n",
    "\n",
    "def avg_pool(image, kernel_size, stride=1, padding='none'):\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50542d91",
   "metadata": {},
   "source": [
    "## Additional Tasks\n",
    "\n",
    "1. The example problems used grayscale images. Modify your solution to support working with images that have multiple color channels.\n",
    "2. Modify the *padding* so that, in the case of an odd number of zeros that need to be added, the input image is primarily extended to the right and downward.\n",
    "3. Modify the *padding* calculation so that it supports values of *stride* other than 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0362c5",
   "metadata": {},
   "source": [
    "## Used Sources and Additional Links\n",
    "\n",
    "- [A guide to convolution arithmetic for deep learning](https://arxiv.org/pdf/1603.07285.pdf)\n",
    "- [Gentle Dive into Math Behind Convolutional Neural Networks](https://towardsdatascience.com/gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9)\n",
    "- [Convolution Image Size, Filter Size, Padding and Stride](https://jamesmccaffrey.wordpress.com/2018/05/30/convolution-image-size-filter-size-padding-and-stride/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea54ac14-3a9b-40b6-9294-dfe9e1c3010e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
